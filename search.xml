<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>小站的更新</title>
      <link href="/posts/9280.html"/>
      <url>/posts/9280.html</url>
      
        <content type="html"><![CDATA[<h3 id="V1-2"><a href="#V1-2" class="headerlink" title="V1.2"></a>V1.2</h3><ol><li>电脑端加入音乐功能</li><li>删除banner上的Github链接</li><li>更改一些图片</li></ol><h3 id="V1-1"><a href="#V1-1" class="headerlink" title="V1.1"></a>V1.1</h3><ol><li>加入烟花点击效果</li><li>更改打赏的图片</li></ol><h3 id="V1-0"><a href="#V1-0" class="headerlink" title="V1.0"></a>V1.0</h3><ol><li>小站成功上线啦，由于是静态网页托管在Github上，不足之处还请谅解。</li></ol>]]></content>
      
      
      <categories>
          
          <category> other </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hexo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习第一天（pytorch学习笔记）</title>
      <link href="/posts/6080.html"/>
      <url>/posts/6080.html</url>
      
        <content type="html"><![CDATA[<h1 id="入坑（2020-4-29）"><a href="#入坑（2020-4-29）" class="headerlink" title="入坑（2020.4.29）"></a>入坑（2020.4.29）</h1><p>喜欢深度学习，喜欢python。<br>看起来torch挺好的。</p><h1 id="torch环境准备"><a href="#torch环境准备" class="headerlink" title="torch环境准备"></a>torch环境准备</h1><ul><li>torch  (1.5.0)</li><li>torchvision  (0.6.0)</li><li>cuda  (10.2)<br><img src="https://img-blog.csdnimg.cn/20200429183137908.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTk3MzYzMA==,size_16,color_FFFFFF,t_70#pic_center" alt=""><br>输入指令执行代码,速度不行的话复制下载链接迅雷打开，可能有惊喜<img src="https://img-blog.csdnimg.cn/20200429183453171.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTk3MzYzMA==,size_16,color_FFFFFF,t_70#pic_center" alt=""><br>环境配好后，执行<pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> pythontorch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre>这时应该返回True.</li></ul><h1 id="一次比赛的代码"><a href="#一次比赛的代码" class="headerlink" title="一次比赛的代码"></a>一次比赛的代码</h1><p>不懂的话直接当普通代码执行，当然本人还是纯小白，代码是copy来的，一次比赛的baseline代码</p><h4 id="加载pytorch框架下的依赖项"><a href="#加载pytorch框架下的依赖项" class="headerlink" title="加载pytorch框架下的依赖项"></a>加载pytorch框架下的依赖项</h4><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> __future__ <span class="token keyword">import</span> print_function<span class="token punctuation">,</span> division<span class="token keyword">import</span> torch<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optim<span class="token keyword">from</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">import</span> lr_scheduler<span class="token keyword">from</span> torch<span class="token punctuation">.</span>autograd <span class="token keyword">import</span> Variable<span class="token keyword">import</span> torchvision<span class="token keyword">from</span> torchvision <span class="token keyword">import</span> datasets<span class="token punctuation">,</span> models<span class="token punctuation">,</span> transforms<span class="token keyword">import</span> time<span class="token keyword">import</span> os</code></pre><h4 id="加载数据集，并分为训练集和测试集"><a href="#加载数据集，并分为训练集和测试集" class="headerlink" title="加载数据集，并分为训练集和测试集"></a>加载数据集，并分为训练集和测试集</h4><pre class=" language-python"><code class="language-python">dataTrans <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>            transforms<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            transforms<span class="token punctuation">.</span>CenterCrop<span class="token punctuation">(</span><span class="token number">224</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token punctuation">]</span><span class="token punctuation">)</span>data_dir <span class="token operator">=</span> <span class="token string">'./images'</span>all_image_datasets <span class="token operator">=</span> datasets<span class="token punctuation">.</span>ImageFolder<span class="token punctuation">(</span>data_dir<span class="token punctuation">,</span> dataTrans<span class="token punctuation">)</span>trainsize <span class="token operator">=</span> int<span class="token punctuation">(</span><span class="token number">0.8</span><span class="token operator">*</span>len<span class="token punctuation">(</span>all_image_datasets<span class="token punctuation">)</span><span class="token punctuation">)</span>testsize <span class="token operator">=</span> len<span class="token punctuation">(</span>all_image_datasets<span class="token punctuation">)</span> <span class="token operator">-</span> trainsizetrain_dataset<span class="token punctuation">,</span> test_dataset <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>random_split<span class="token punctuation">(</span>all_image_datasets<span class="token punctuation">,</span><span class="token punctuation">[</span>trainsize<span class="token punctuation">,</span>testsize<span class="token punctuation">]</span><span class="token punctuation">)</span>image_datasets <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'train'</span><span class="token punctuation">:</span>train_dataset<span class="token punctuation">,</span><span class="token string">'val'</span><span class="token punctuation">:</span>test_dataset<span class="token punctuation">}</span>dataloders <span class="token operator">=</span> <span class="token punctuation">{</span>x<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>image_datasets<span class="token punctuation">[</span>x<span class="token punctuation">]</span><span class="token punctuation">,</span>                                                 batch_size<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span>                                                 shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>                                                 num_workers<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span> <span class="token keyword">for</span> x <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">,</span> <span class="token string">'val'</span><span class="token punctuation">]</span><span class="token punctuation">}</span>dataset_sizes <span class="token operator">=</span> <span class="token punctuation">{</span>x<span class="token punctuation">:</span> len<span class="token punctuation">(</span>image_datasets<span class="token punctuation">[</span>x<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">for</span> x <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">,</span> <span class="token string">'val'</span><span class="token punctuation">]</span><span class="token punctuation">}</span>    <span class="token comment" spellcheck="true"># use gpu or not</span>use_gpu <span class="token operator">=</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><h4 id="开始训练"><a href="#开始训练" class="headerlink" title="开始训练"></a>开始训练</h4><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">train_model</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> lossfunc<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> scheduler<span class="token punctuation">,</span> num_epochs<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    start_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>    best_model_wts <span class="token operator">=</span> model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span>    best_acc <span class="token operator">=</span> <span class="token number">0.0</span>    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span>num_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Epoch {}/{}'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>epoch<span class="token punctuation">,</span> num_epochs <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'-'</span> <span class="token operator">*</span> <span class="token number">10</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># Each epoch has a training and validation phase</span>        <span class="token keyword">for</span> phase <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">,</span> <span class="token string">'val'</span><span class="token punctuation">]</span><span class="token punctuation">:</span>            <span class="token keyword">if</span> phase <span class="token operator">==</span> <span class="token string">'train'</span><span class="token punctuation">:</span>                scheduler<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>                model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Set model to training mode</span>            <span class="token keyword">else</span><span class="token punctuation">:</span>                model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token boolean">False</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Set model to evaluate mode</span>            running_loss <span class="token operator">=</span> <span class="token number">0.0</span>            running_corrects <span class="token operator">=</span> <span class="token number">0.0</span>            <span class="token comment" spellcheck="true"># Iterate over data.</span>            <span class="token keyword">for</span> data <span class="token keyword">in</span> dataloders<span class="token punctuation">[</span>phase<span class="token punctuation">]</span><span class="token punctuation">:</span>                <span class="token comment" spellcheck="true"># get the inputs</span>                inputs<span class="token punctuation">,</span> labels <span class="token operator">=</span> data                <span class="token comment" spellcheck="true"># wrap them in Variable</span>                <span class="token keyword">if</span> use_gpu<span class="token punctuation">:</span>                    inputs <span class="token operator">=</span> Variable<span class="token punctuation">(</span>inputs<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>                    labels <span class="token operator">=</span> Variable<span class="token punctuation">(</span>labels<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>                <span class="token keyword">else</span><span class="token punctuation">:</span>                    inputs<span class="token punctuation">,</span> labels <span class="token operator">=</span> Variable<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span><span class="token punctuation">,</span> Variable<span class="token punctuation">(</span>labels<span class="token punctuation">)</span>                <span class="token comment" spellcheck="true"># zero the parameter gradients</span>                optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>                <span class="token comment" spellcheck="true"># forward</span>                outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>                _<span class="token punctuation">,</span> preds <span class="token operator">=</span> torch<span class="token punctuation">.</span>max<span class="token punctuation">(</span>outputs<span class="token punctuation">.</span>data<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>                loss <span class="token operator">=</span> lossfunc<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> labels<span class="token punctuation">)</span>                <span class="token comment" spellcheck="true"># backward + optimize only if in training phase</span>                <span class="token keyword">if</span> phase <span class="token operator">==</span> <span class="token string">'train'</span><span class="token punctuation">:</span>                    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>                    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>                <span class="token comment" spellcheck="true"># statistics</span>                running_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>data                running_corrects <span class="token operator">+=</span> torch<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>preds <span class="token operator">==</span> labels<span class="token punctuation">.</span>data<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>            epoch_loss <span class="token operator">=</span> running_loss <span class="token operator">/</span> dataset_sizes<span class="token punctuation">[</span>phase<span class="token punctuation">]</span>            epoch_acc <span class="token operator">=</span> running_corrects <span class="token operator">/</span> dataset_sizes<span class="token punctuation">[</span>phase<span class="token punctuation">]</span>            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'{} Loss: {:.4f} Acc: {:.4f}'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>                phase<span class="token punctuation">,</span> epoch_loss<span class="token punctuation">,</span> epoch_acc<span class="token punctuation">)</span><span class="token punctuation">)</span>            <span class="token comment" spellcheck="true"># deep copy the model</span>            <span class="token keyword">if</span> phase <span class="token operator">==</span> <span class="token string">'val'</span> <span class="token operator">and</span> epoch_acc <span class="token operator">></span> best_acc<span class="token punctuation">:</span>                best_acc <span class="token operator">=</span> epoch_acc                best_model_wts <span class="token operator">=</span> model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span>    elapsed_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> start_time    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Training complete in {:.0f}m {:.0f}s'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>        elapsed_time <span class="token operator">//</span> <span class="token number">60</span><span class="token punctuation">,</span> elapsed_time <span class="token operator">%</span> <span class="token number">60</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Best val Acc: {:4f}'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>best_acc<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># load best model weights</span>    model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>best_model_wts<span class="token punctuation">)</span>    <span class="token keyword">return</span> model<span class="token comment" spellcheck="true"># get model and replace the original fc layer with your fc layer</span>model_ft <span class="token operator">=</span> models<span class="token punctuation">.</span>resnet50<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>num_ftrs <span class="token operator">=</span> model_ft<span class="token punctuation">.</span>fc<span class="token punctuation">.</span>in_featuresmodel_ft<span class="token punctuation">.</span>fc <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>num_ftrs<span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token keyword">if</span> use_gpu<span class="token punctuation">:</span>    model_ft <span class="token operator">=</span> model_ft<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># define loss function</span>lossfunc <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># setting optimizer and trainable parameters</span> <span class="token comment" spellcheck="true">#   params = model_ft.parameters()</span> <span class="token comment" spellcheck="true"># list(model_ft.fc.parameters())+list(model_ft.layer4.parameters())</span><span class="token comment" spellcheck="true">#params = list(model_ft.fc.parameters())+list( model_ft.parameters())</span>params <span class="token operator">=</span> list<span class="token punctuation">(</span>model_ft<span class="token punctuation">.</span>fc<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>optimizer_ft <span class="token operator">=</span> optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>params<span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># Decay LR by a factor of 0.1 every 7 epochs</span>exp_lr_scheduler <span class="token operator">=</span> lr_scheduler<span class="token punctuation">.</span>StepLR<span class="token punctuation">(</span>optimizer_ft<span class="token punctuation">,</span> step_size<span class="token operator">=</span><span class="token number">7</span><span class="token punctuation">,</span> gamma<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span>model_ft <span class="token operator">=</span> train_model<span class="token punctuation">(</span>model<span class="token operator">=</span>model_ft<span class="token punctuation">,</span>                           lossfunc<span class="token operator">=</span>lossfunc<span class="token punctuation">,</span>                           optimizer<span class="token operator">=</span>optimizer_ft<span class="token punctuation">,</span>                           scheduler<span class="token operator">=</span>exp_lr_scheduler<span class="token punctuation">,</span>                           num_epochs<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span></code></pre><pre><code>Epoch 0/4----------C:\Users\16413\anaconda3\lib\site-packages\torch\optim\lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate  &quot;https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate&quot;, UserWarning)train Loss: 0.0750 Acc: 0.6700val Loss: 0.0436 Acc: 0.8200Epoch 1/4----------train Loss: 0.0399 Acc: 0.8250val Loss: 0.0345 Acc: 0.8470Epoch 2/4----------train Loss: 0.0330 Acc: 0.8473val Loss: 0.0303 Acc: 0.8610Epoch 3/4----------train Loss: 0.0300 Acc: 0.8575val Loss: 0.0293 Acc: 0.8650Epoch 4/4----------train Loss: 0.0288 Acc: 0.8643val Loss: 0.0281 Acc: 0.8750Training complete in 6m 31sBest val Acc: 0.875000</code></pre><pre class=" language-python"><code class="language-python">torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model_ft<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'./model.pth'</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"done"</span><span class="token punctuation">)</span></code></pre><pre><code>done</code></pre><h1 id="结束语"><a href="#结束语" class="headerlink" title="结束语"></a>结束语</h1><p>热爱是一件很美好的事。</p><p>读者有兴趣的话，<br>可以百度或知乎一下，深度学习、神经网络、resnet等一堆概念。</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> torch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/posts/3eeb.html"/>
      <url>/posts/3eeb.html</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><pre class=" language-bash"><code class="language-bash">$ hexo new <span class="token string">"My New Post"</span></code></pre><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><pre class=" language-bash"><code class="language-bash">$ hexo server</code></pre><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><pre class=" language-bash"><code class="language-bash">$ hexo generate</code></pre><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><pre class=" language-bash"><code class="language-bash">$ hexo deploy</code></pre><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p><blockquote><p>以上为官方文档<br><strong>想建站的，可以参考：</strong><br><a href="https://www.jianshu.com/p/0a8d738a5620" target="_blank" rel="noopener">https://www.jianshu.com/p/0a8d738a5620</a><br><a href="https://yafine66.gitee.io/" target="_blank" rel="noopener">https://yafine66.gitee.io/</a></p></blockquote>]]></content>
      
      
      <categories>
          
          <category> other </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hexo </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
